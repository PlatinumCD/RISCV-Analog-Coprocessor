@article{10.1145/1964218.1964225,
author = {Rodrigues, A. F. and Hemmert, K. S. and Barrett, B. W. and Kersey, C. and Oldfield, R. and Weston, M. and Risen, R. and Cook, J. and Rosenfeld, P. and Cooper-Balis, E. and Jacob, B.},
title = {The structural simulation toolkit},
year = {2011},
issue_date = {March 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0163-5999},
url = {https://doi.org/10.1145/1964218.1964225},
doi = {10.1145/1964218.1964225},
abstract = {As supercomputers grow, understanding their behavior and performance has become increasingly challenging. New hurdles in scalability, programmability, power consumption, reliability, cost, and cooling are emerging, along with new technologies such as 3D integration, GP-GPUs, silicon-photonics, and other "game changers". Currently, they HPC community lacks a unified toolset to evaluate these technologies and design for these challenges.To address this problem, a number of institutions have joined together to create the Structural Simulation Toolkit (SST), an open, modular, parallel, multi-criteria, multi-scale simulation framework. The SST includes a number of processor, memory, and network models. The SST has been used in a variety of network, memory, and application studies and aims to become the standard simulation framework for designing and procuring HPC systems.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = mar,
pages = {37–42},
numpages = {6},
keywords = {simulation, performance analysis, architecture, SST}
}

@inproceedings{10.1007/978-3-031-40843-4_40,
author = {Berger-Vergiat, Luc and Cardwell, Suma G. and Feinberg, Ben and Hammond, Simon D. and Hughes, Clayton and Levenhagen, Michael and Pedretti, Kevin},
title = {Evaluation of&nbsp;HPC Workloads Running on&nbsp;Open-Source RISC-V Hardware},
year = {2023},
isbn = {978-3-031-40842-7},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-40843-4_40},
doi = {10.1007/978-3-031-40843-4_40},
abstract = {The emerging RISC-V ecosystem has the potential to improve the speed, fidelity, and quality of hardware/software co-design R &D activities. However, the suitability of the RISC-V ecosystem for co-design targeting HPC use cases is not yet well understood. In this paper, we examine the performance of several HPC benchmark workloads running on simulated open-source hardware RISC-V cores running under the FireSim FPGA-accelerated simulation tool. To provide a realistic and reproducible HPC software stack, we port the Spack package manager to RISC-V and use it to build our workloads. Our key finding is that each of the RISC-V cores evaluated is capable of running complex HPC workloads executing for long durations under simulation, with simulation rates of approximately 1/50th real-time. Additionally we provide a baseline set of performance results that can be compared against in future studies. Our results highlight the readiness of the RISC-V ecosystem for performing open co-design activities for HPC. We expect performance to improve as co-design activities targeting RISC-V ramp up and the RISC-V community makes further contributions to this space.},
booktitle = {High Performance Computing: ISC High Performance 2023 International Workshops, Hamburg, Germany, May 21–25, 2023, Revised Selected Papers},
pages = {538–551},
numpages = {14},
keywords = {Simulation, Open-Source Hardware, Benchmarking, HPC, RISC-V},
location = {Hamburg, Germany}
}

@inproceedings{10.1145/3637543.3654616,
author = {Leidel, John and Donofrio, David and Kabrick, Ryan and Killough, Lee and Griesser, Kenneth},
title = {Scaling SST for Extreme Scale System Simulation},
year = {2024},
isbn = {9798400704925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637543.3654616},
doi = {10.1145/3637543.3654616},
abstract = {The IARPA AGILE program is a program designed to create an entirely new high performance computing architecture for data-intensive computing applications. More specifically, the objective of the AGILE initiative is to design and model HPC systems which are capable of executing extreme-scale applications in graph analytics, gene/protein sequencing and graph neural networks.The program is a two-phased approach whereby the initial phase of research and development must be completed entirely in simulation. For this, IARPA has required that the participants utilize the Sandia Structural Simulation Toolkit (SST) to perform high fidelity and trace-based simulations of the candidate designs at a scale well beyond any current computer aided design flows. This work presents a scalability study and a set of execution methodologies performed to prove the feasibility and scalability of SST for the IARPA AGILE program goal of simulating a full system entirely in software.},
booktitle = {Proceedings of the 21st ACM International Conference on Computing Frontiers: Workshops and Special Sessions},
pages = {87–93},
numpages = {7},
keywords = {PDES, discrete event simulation, exascale, parallel simulation},
location = {Ischia, Italy},
series = {CF '24 Companion}
}

@INPROCEEDINGS{8416841,
  author={Feinberg, Ben and Vengalam, Uday Kumar Reddy and Whitehair, Nathan and Wang, Shibo and Ipek, Engin},
  booktitle={2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)}, 
  title={Enabling Scientific Computing on Memristive Accelerators}, 
  year={2018},
  volume={},
  number={},
  pages={367-382},
  keywords={Sparse matrices;Hardware;Machine learning;Graphics processing units;Mathematical model;Computational modeling;Linear algebra;Accelerator Architectures;Resistive RAM},
  doi={10.1109/ISCA.2018.00039}}


  @inproceedings{10.1145/3581784.3607077,
author = {Song, Linghao and Chen, Fan and Li, Hai and Chen, Yiran},
title = {ReFloat: Low-Cost Floating-Point Processing in ReRAM for Accelerating Iterative Linear Solvers},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581784.3607077},
doi = {10.1145/3581784.3607077},
abstract = {Resistive random access memory (ReRAM) is a promising technology that can perform low-cost and in-situ matrix-vector multiplication (MVM) in analog domain. Scientific computing requires high-precision floating-point (FP) processing. However, performing floating-point computation in ReRAM is challenging because of high hardware cost and execution time due to the large FP value range. In this work we present ReFloat, a data format and an accelerator architecture, for low-cost and high-performance floating-point processing in ReRAM for iterative linear solvers. ReFloat matches the ReRAM crossbar hardware and represents a block of FP values with reduced bits and an optimized exponent base for a high range of dynamic representation. Thus, ReFloat achieves less ReRAM crossbar consumption and fewer processing cycles and overcomes the noncovergence issue in a prior work. The evaluation on the SuiteSparse matrices shows ReFloat achieves 5.02\texttimes{} to 84.28\texttimes{} improvement in terms of solver time compared to a state-of-the-art ReRAM based accelerator.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {75},
numpages = {15},
keywords = {processing-in-memory, accelerator, ReRAM, floating-point},
location = {Denver, CO, USA},
series = {SC '23}
}

@article{LeGallo2017MixedprecisionIC,
  title={Mixed-precision in-memory computing},
  author={Manuel Le Gallo and Abu Sebastian and Roland Mathis and Matteo Manica and Heiner Giefers and Tomas Tuma and Costas Bekas and Alessandro Curioni and Evangelos Eleftheriou},
  journal={Nature Electronics},
  year={2017},
  volume={1},
  pages={246 - 253},
  url={https://doi.org/10.1038/s41928-018-0054-8}
}

@ARTICLE{Genov01,
  author={Genov, R. and Cauwenberghs, G.},
  journal={IEEE Trans. Circuits Syst. II, Analog Digit. Signal Process.}, 
  title={Charge-mode parallel architecture for vector-matrix multiplication}, 
  year={2001},
  volume={48},
  number={10},
  pages={930-936},
  keywords={Parallel architectures;Random access memory;Support vector machines;Concurrent computing;Throughput;Charge coupled devices;CMOS technology;Machine vision;Computer vision;Very large scale integration},
  doi={10.1109/82.974781}}

  @article{AnalogReview,
    author = {Xiao, T. Patrick and Bennett, Christopher H. and Feinberg, Ben and Agarwal, Sapan and Marinella, Matthew J.},
    title = {Analog architectures for neural network acceleration based on non-volatile memory},
    journal = {Appl. Phys. Rev.},
    volume = {7},
    number = {3},
    pages = {031301},
    year = {2020},
    month = {July},
    issn = {1931-9401},
    doi = {10.1063/1.5143815},
    eprint = {https://pubs.aip.org/aip/apr/article-pdf/doi/10.1063/1.5143815/19740151/031301\_1\_online.pdf},
}

@article{ambrogio-energy-2023,
    author = {Ambrogio, S. and Narayanan, P. and Okazaki, A. and Fasoli, A. and Mackin, C. and Hosokawa, K. and Nomura, A. and Yasuda, T. and Chen, A. and Friz, A. and Ishii, M. and Luquin, J. and Kohda, Y. and Saulnier, N. and Brew, K. and Choi, S. and Ok, I. and Philip, T. and Chan, V. and Silvestre, C. and Ahsan, I. and Narayanan, V. and Tsai, H. and Burr, G. W.},
    date = {2023/08/01},
    date-added = {2025-04-11 22:27:49 -0400},
    date-modified = {2025-04-11 22:27:49 -0400},
    doi = {10.1038/s41586-023-06337-5},
    id = {Ambrogio2023},
    isbn = {1476-4687},
    journal = {Nature},
    number = {7975},
    pages = {768--775},
    title = {An analog-AI chip for energy-efficient speech recognition and transcription},
    url = {https://doi.org/10.1038/s41586-023-06337-5},
    volume = {620},
    year = {2023},
}

@techreport{Asanović:EECS-2016-17,
    Author= {Asanović, Krste and Avizienis, Rimas and Bachrach, Jonathan and Beamer, Scott and Biancolin, David and Celio, Christopher and Cook, Henry and Dabbelt, Daniel and Hauser, John and Izraelevitz, Adam and Karandikar, Sagar and Keller, Ben and Kim, Donggyu and Koenig, John and Lee, Yunsup and Love, Eric and Maas, Martin and Magyar, Albert and Mao, Howard and Moreto, Miquel and Ou, Albert and Patterson, David A. and Richards, Brian and Schmidt, Colin and Twigg, Stephen and Vo, Huy and Waterman, Andrew},
    Title= {The Rocket Chip Generator},
    Year= {2016},
    Month= {Apr},
    Url= {http://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-17.html},
    Number= {UCB/EECS-2016-17},
    Abstract= {Rocket Chip is an open-source Sysem-on-Chip design generator that emits synthesizable RTL. It leverages the Chisel hardware construction language to compose a library of sophisticated generators for cores, caches, and interconnects into an integrated SoC. Rocket Chip generates general-purpose processor cores that use the open RISC-V ISA, and provides both an in-order core generator (Rocket) and an out-of-order core generator (BOOM). For SoC designers interested in utilizing heterogeneous specialization for added efficiency gains, Rocket Chip supports the integration of custom accelerators in the form of instruction set extensions, coprocessors, or fully independent novel cores. Rocket Chip has been taped out (manufactured) eleven times, and yielded functional silicon prototypes capable of booting Linux.},
}

@INPROCEEDINGS {10820793,
author = { Brown, Nick and Barton, Ryan },
booktitle = { SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis },
title = {{ Accelerating stencils on the Tenstorrent Grayskull RISC-V accelerator }},
year = {2024},
volume = {},
ISSN = {},
pages = {1690-1700},
abstract = { The RISC-V Instruction Set Architecture (ISA) has enjoyed phenomenal growth in recent years, however it still to gain popularity in HPC. Whilst adopting RISC-V CPU solutions in HPC might be some way off, RISC-V based PCIe accelerators offer a middle ground where vendors benefit from the flexibility of RISC-V yet fit into existing systems. In this paper we focus on the Tenstorrent Grayskull PCIe RISC-V based accelerator which, built upon Tensix cores, decouples data movement from compute. Using the Jacobi iterative method as a vehicle, we explore the suitability of stencils on the Grayskull e150. We explore best practice in structuring these codes for the accelerator and demonstrate that the e150 provides similar performance to a Xeon Platinum CPU (albeit BF16 vs FP32) but the e150 uses around five times less energy. Over four e150s we obtain around four times the CPU performance, again at around five times less energy. },
keywords = {Jacobian matrices;Codes;Instruction sets;High performance computing;Conferences;Platinum;Computer architecture;Iterative methods;Best practices},
doi = {10.1109/SCW63240.2024.00211},
url = {https://doi.ieeecomputersociety.org/10.1109/SCW63240.2024.00211},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Nov}



@inproceedings{10.1145/3297858.3304049,
author = {Ankit, Aayush and Hajj, Izzat El and Chalamalasetti, Sai Rahul and Ndu, Geoffrey and Foltin, Martin and Williams, R. Stanley and Faraboschi, Paolo and Hwu, Wen-mei W and Strachan, John Paul and Roy, Kaushik and Milojicic, Dejan S.},
title = {PUMA: A Programmable Ultra-efficient Memristor-based Accelerator for Machine Learning Inference},
year = {2019},
isbn = {9781450362405},
url = {https://doi.org/10.1145/3297858.3304049},
doi = {10.1145/3297858.3304049},
booktitle = {Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {715–731},
numpages = {17},
keywords = {accelerators, machine learning, memristors, neural networks},
location = {Providence, RI, USA},
series = {ASPLOS '19}
}

@ARTICLE{9669117,
  author={Xiao, T. Patrick and Feinberg, Ben and Bennett, Christopher H. and Agrawal, Vineet and Saxena, Prashant and Prabhakar, Venkatraman and Ramkumar, Krishnaswamy and Medu, Harsha and Raghavan, Vijay and Chettuvetty, Ramesh and Agarwal, Sapan and Marinella, Matthew J.},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, 
  title={An Accurate, Error-Tolerant, and Energy-Efficient Neural Network Inference Engine Based on SONOS Analog Memory}, 
  year={2022},
  volume={69},
  number={4},
  pages={1480-1493},
  keywords={SONOS devices;Neural networks;Transistors;Logic gates;Programming;Memristors;Analog memory;SONOS;charge trap memory;neuromorphic;neural network;analog;in-memory computing;inference accelerator},
  doi={10.1109/TCSI.2021.3134313}}
